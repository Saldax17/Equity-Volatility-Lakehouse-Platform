# ğŸ“ˆ Equity Volatility Lakehouse Platform (EVLP)

**EVLP** es una plataforma end-to-end diseÃ±ada para analizar y predecir la volatilidad de acciones del mercado estadounidense usando una arquitectura moderna basada en **Lakehouse** (Medallion: Bronzeâ€“Silverâ€“Gold), procesamiento distribuido con **Spark**, APIs financieras y modelos de **Machine Learning**.

<p align="left">
  <img src="https://img.shields.io/badge/Python-3.9+-blue?logo=python" />
  <img src="https://img.shields.io/badge/Spark-3.x-orange?logo=apache-spark" />
  <img src="https://img.shields.io/badge/AWS%20Glue-ETL-yellow?logo=amazon-aws" />
  <img src="https://img.shields.io/badge/Apache%20Iceberg-Lakehouse-green?logo=apache" />
  <img src="https://img.shields.io/badge/ML-Classification-red?logo=google" />
</p>

---

# ğŸ“¥ 0. Ingesta de Datos desde APIs (Raw Ingestion Layer)

La plataforma inicia con una fase de ingesta avanzada que combina datos de **EODHD**, **Alpaca** e **iShares** para construir el dataset base que alimenta la capa Bronze en el Lakehouse.

ğŸ“„ CÃ³digo: `ingestion/consulta_de_datos_con_apis.py`  


### âœ” EODHD â€“ Ãndices y Constituyentes HistÃ³ricos
- Descarga de Ã­ndices: **GSPC**, **MID**, **SML**
- ObtenciÃ³n de constituyentes histÃ³ricos diarios
- Limpieza de sufijos en tickers (`_old`, `_old1`, `_old2`)
- Reemplazo de caracteres invÃ¡lidos (`-` â†’ `.`)
- NormalizaciÃ³n a timezone **America/New_York**

### âœ” iShares â€“ ETF Constituents
- Carga de componentes del ETF **IWB** desde archivo XLS
- GeneraciÃ³n de listas de sÃ­mbolos para consulta masiva

### âœ” Alpaca â€“ Historical Bars (30m)
- Descarga de datos OHLCV en intervalos de 30 minutos
- Rango histÃ³rico: **2007 â€“ 2025**
- Ajustes: RAW / ALL
- Uso de:
  - MyAlpacaJob  
  - MyAlpacaStock  
  - StockHistoricalDataClient  

### âœ” Dataset Final
- Ensamble diario de constituyentes activos
- Descarga selectiva de barras 30m por sÃ­mbolo
- PreparaciÃ³n final para ser almacenado como **Bronze** en S3

---

# ğŸ§© 1. DescripciÃ³n del Proyecto

La plataforma procesa datos financieros a travÃ©s de las capas Bronze â†’ Silver â†’ Gold, realiza feature engineering avanzado y entrena modelos de machine learning orientados a clasificar volatilidad.

Incluye:
- Ingesta desde APIs financieras  
- Procesamiento distribuido (Spark / AWS Glue)  
- Lakehouse con Apache Iceberg  
- Feature engineering (volatilidad y lookbacks)  
- Modelos ML de clasificaciÃ³n y clustering  
- VisualizaciÃ³n y anÃ¡lisis descriptivo  

---

# ğŸ— 2. Arquitectura del Proyecto

## ğŸ”¶ Medallion Architecture (Lakehouse)

### ğŸ¥‰ Bronze â€“ Raw Layer
- Datos crudos desde Alpaca, EODHD e iShares  
- Sin transformaciÃ³n  
- Historial de constituyentes y OHLCV 30m  

---

### ğŸ¥ˆ Silver â€“ Clean Layer
- NormalizaciÃ³n de timestamps (NY timezone)  
- Rejilla temporal completa (30 minutos)  
- ImputaciÃ³n forward-fill / backfill  
- UniÃ³n sÃ­mbolo Ã— timestamp  

---

### ğŸ¥‡ Gold â€“ Feature Layer
Feature engineering orientado a series de tiempo:
- % Highâ€“Low  
- % Openâ€“Close  
- Gaps de apertura  
- Lookbacks: 1d, 7d, 28d, 112d  

---

# âš™ï¸ 3. Pipeline de Procesamiento (AWS Glue â€¢ Spark â€¢ Iceberg)

## ğŸ¥ˆ Fase 1 â€” Limpieza y Rejilla Temporal (Silver Layer)
ğŸ“„ CÃ³digo: `processing/procesamiento_fase_1.py`  
Origen tÃ©cnico: :contentReference[oaicite:1]{index=1}

Incluye:
- Lectura desde Iceberg (Bronze)  
- SelecciÃ³n aleatoria de sÃ­mbolos representativos  
- ConstrucciÃ³n de rejilla temporal (30 min)  
- Join sÃ­mbolo Ã— timestamp  
- Forward-fill y backfill de OHLCV  
- Limpieza de volumen y trade_count  
- Escritura en Iceberg:
  **`proyecto1db.stock_iceberg_sample`**

---

## ğŸ¥‡ Fase 2 â€” Feature Engineering (Gold Layer)
ğŸ“„ CÃ³digo: `processing/procesamiento_fase_2.py`  
Origen tÃ©cnico: :contentReference[oaicite:2]{index=2}

Incluye:
- CÃ¡lculo de volatilidad (% Highâ€“Low, % Openâ€“Close)  
- Gap de apertura vs close previo  
- Lookbacks:
  - 1d, 7d, 28d, 112d  
- GeneraciÃ³n de columnas `pct_change_<period>`  
- Limpieza de columnas auxiliares  
- Ordenamiento por sÃ­mbolo + timestamp  

---

# ğŸ§  4. ML Pipeline

Modelos implementados:
- Logistic Regression  
- Decision Tree  
- Random Forest  
- Gradient Boosting  
- XGBoost  
- K-Means (clustering)

EvaluaciÃ³n del desempeÃ±o:
- **F1-score** como mÃ©trica principal  

---

# ğŸ“‚ 5. Estructura del Repositorio

```bash
Equity-Volatility-Lakehouse-Platform/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ parameters.py
â”‚
â”œâ”€â”€ data_alpaca/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ alpa.py
â”‚   â””â”€â”€ bars.py
â”‚
â”œâ”€â”€ data_apis/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ my_alpaca.py
â”‚   â”œâ”€â”€ my_eodhd.py
â”‚   â”œâ”€â”€ my_ishares.py
â”‚   â”œâ”€â”€ my_models.py
â”‚   â”œâ”€â”€ my_stock_functions.py
â”‚   â””â”€â”€ helpers.py
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ Informe_Final.pdf
â”‚   â”œâ”€â”€ Presentacion.pdf
â”‚   â”œâ”€â”€ Preliminar.pdf
â”‚   â”œâ”€â”€ Propuesta.pdf
â”‚   â””â”€â”€ arquitectura_medallion.drawio
â”‚
â”œâ”€â”€ ingestion/
â”‚   â””â”€â”€ consulta_de_datos_con_apis.ipynb   
â”‚
â”œâ”€â”€ processing/
â”‚   â”œâ”€â”€ Procesamiento_fase_1.ipynb
â”‚   â””â”€â”€ Procesamiento_fase_2.ipynb 
â”‚
â”œâ”€â”€ architecture/
â”‚   â”œâ”€â”€ arquitectura_medallion.png
â”‚   â”œâ”€â”€ pipeline_completo.png
â”‚   â””â”€â”€ arquitectura_aws.png
â”‚
â”œâ”€â”€ data/     # (Ignorado en GitHub)
â”‚   â”œâ”€â”€ bronze/
â”‚   â”œâ”€â”€ silver/
â”‚   â””â”€â”€ gold/

```


# âš™ï¸ 4. InstalaciÃ³n

### Requisitos
- Python 3.9+
- pip
- Cuenta en Alpaca y EODHD (para API keys)
- Spark 3.x (si corres procesamiento local)

```bash
git clone https://github.com/<tu-usuario>/proyecto-volatilidad.git
cd proyecto-volatilidad
pip install -r requirements.txt
```



